{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Boosting.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMxjARIunAfhsygWVfIYVye",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Lursen/Ensemble-methods/blob/main/Boosting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Загрузка данных, инициализация весов каждого примера выборки"
      ],
      "metadata": {
        "id": "AVMsdpoKxO0z"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AGRe_wnes4Pp"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#bool_in=0\n",
        "#real_in=51\n",
        "#bool_out=2\n",
        "#real_out=0\n",
        "#training_examples=345\n",
        "#validation_examples=173\n",
        "#test_examples=172\n",
        "\n",
        "data = np.loadtxt('card2.dt')\n",
        "X = data[:, 0:51]\n",
        "Y = data[:, 52]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, train_size=0.9, random_state=42)\n",
        "# Weights of samples\n",
        "X_weights = np.zeros(np.shape(X_train)[0])\n",
        "X_weights = X_weights + 1/np.shape(X_train)[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Класс сети прямого распространения"
      ],
      "metadata": {
        "id": "OU_LqKh8yZgo"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wYK3MLyrqbtV"
      },
      "source": [
        "import torch \n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "class Feedforward(torch.nn.Module):\n",
        "        def __init__(self, input_size, hidden_size):\n",
        "            super(Feedforward, self).__init__()\n",
        "            self.input_size = input_size\n",
        "            self.hidden_size  = hidden_size\n",
        "            self.fc1 = torch.nn.Linear(self.input_size, self.hidden_size)\n",
        "            self.relu = torch.nn.ReLU()\n",
        "            self.fc2 = torch.nn.Linear(self.hidden_size, 1)\n",
        "            self.sigmoid = torch.nn.Sigmoid()\n",
        "            self.tanh = torch.nn.Tanh()\n",
        "\n",
        "        def forward(self, x):\n",
        "            hidden = self.fc1(x)\n",
        "            sigmoid = self.sigmoid(hidden)\n",
        "            output = self.fc2(sigmoid)\n",
        "            output = self.sigmoid(output)\n",
        "            return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Функции обучения комитета"
      ],
      "metadata": {
        "id": "K5wnq9jgz35X"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TWZu-XFvs4LI"
      },
      "source": [
        "import random\n",
        "def train_commitee(m, x,y,w, x_test,y_test):\n",
        "  NN = [[] for i in range(m)]\n",
        "  NN_accuracy = [[] for i in range(m)]\n",
        "  NN_weight_err = [[] for i in range(m)]\n",
        "\n",
        "  samples_w = np.asarray(w)\n",
        "  samples_x = np.asarray(x)\n",
        "  samples_y = np.asarray(y)\n",
        "  t = 51\n",
        "\n",
        "  for i in range(0,m):\n",
        "    NN[i] = Feedforward(t, 50)\n",
        "    criterion = torch.nn.MSELoss()\n",
        "    optimizer = torch.optim.SGD(NN[i].parameters(), lr = 0.1)\n",
        "    NN_errors = []\n",
        "    NN_weights = []\n",
        "    NN_werr = 0\n",
        "    # training\n",
        "    NN[i].train()\n",
        "    NN[i].double()\n",
        "    epoch = 1000\n",
        "\n",
        "    for epoch in range(epoch):\n",
        "      rnd = np.random.randint(0,np.shape(samples_x)[0])\n",
        "      xs = torch.from_numpy(samples_x[rnd])\n",
        "      ys = torch.tensor(samples_y[rnd])\n",
        "      optimizer.zero_grad()\n",
        "      # Forward pass\n",
        "      y_pred = NN[i](xs)\n",
        "      # Compute Loss\n",
        "      loss = criterion(y_pred.squeeze(), ys)\n",
        "      # Get binary answer\n",
        "      answer = 0\n",
        "      if (y_pred.item() >= 0.8):\n",
        "        answer = 1\n",
        "      # weighted loss\n",
        "      r = 1\n",
        "      if (answer == ys.item()):\n",
        "        r = 0\n",
        "      weighted_loss = samples_w[rnd]*r\n",
        "\n",
        "      NN_errors.append(weighted_loss)\n",
        "      NN_weights.append(samples_w[rnd])\n",
        "      NN_accuracy[i].append(1-np.abs(y_pred.item() - ys.item()))\n",
        "      # Backward pass\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      \n",
        "    em = (np.sum(np.asarray(NN_errors))/np.sum(np.asarray(NN_weights)))\n",
        "    NN_werr = np.log((1.0-em)/em) \n",
        "    NN_weight_err[i] = NN_werr\n",
        "    #print(NN_weight_err[i])\n",
        "    # compute sample error and new weights\n",
        "    for s in range(samples_y.shape[0]):\n",
        "      xs = torch.from_numpy(x[s])\n",
        "      y_pred = NN[i](xs)\n",
        "      answer = 0\n",
        "      if (y_pred.item() >= 0.8):\n",
        "        answer = 1\n",
        "      samples_err = 0\n",
        "      if (answer==y[s]):\n",
        "        samples_err = 1\n",
        "      samples_w[s] = samples_w[s]*np.exp(NN_werr*samples_err)\n",
        "\n",
        "    # create new training set\n",
        "    rn = list(range(0,samples_y.shape[0]))\n",
        "    samples_idx = random.choices(rn, weights=samples_w, k = samples_y.shape[0])\n",
        "    for s in range(samples_y.shape[0]):\n",
        "      samples_x[s] = x[samples_idx[s]]\n",
        "      samples_y[s] = y[samples_idx[s]]\n",
        "\n",
        "  accuracy = [[] for i in range(m)]\n",
        "  for i in range(0,m):\n",
        "    for t in range(0,100):\n",
        "      rnd = np.random.randint(0,np.shape(x_test)[0])\n",
        "      xs = torch.from_numpy(x_test[rnd])\n",
        "      y_pred = NN[i](xs)\n",
        "      acc =  1-np.abs(y_pred.item() - y_test[rnd])\n",
        "      NN_accuracy[i].append(acc)\n",
        "  \n",
        "    accuracy[i] = np.mean(np.asarray(NN_accuracy[i]))\n",
        "\n",
        "  return NN, accuracy, NN_weight_err\n",
        "\n",
        "def get_commitee_accuracy(NN, cl_err, x_test, y_test):\n",
        "  accuracy = []\n",
        "\n",
        "  for t in range(100):\n",
        "    rnd = np.random.randint(0,np.shape(x_test)[0])\n",
        "    xs = torch.from_numpy(x_test[rnd])\n",
        "    answer = 0\n",
        "    for i in range(0,np.shape(NN)[0]):\n",
        "      y_pred = NN[i](xs)\n",
        "      answer = answer + y_pred#(np.abs(cl_err[i])*y_pred.item())\n",
        "\n",
        "    if (answer/np.shape(NN)[0] >= 0.6):\n",
        "      answer = 1\n",
        "    else:\n",
        "      answer = 0\n",
        "    accuracy.append(1-np.abs(answer - y_test[rnd]))\n",
        "\n",
        "  acc_mean = np.mean(np.asarray(accuracy))\n",
        "  std = np.std(np.asarray(accuracy))\n",
        "  return acc_mean, std"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "daP4z80JrA2N"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#bool_in=0\n",
        "#real_in=51\n",
        "#bool_out=2\n",
        "#real_out=0\n",
        "#training_examples=345\n",
        "#validation_examples=173\n",
        "#test_examples=172\n",
        "\n",
        "data = np.loadtxt('card2.dt')\n",
        "X = data[:, 0:51]\n",
        "Y = data[:, 52]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, train_size=0.9, random_state=42)\n",
        "# Weights of samples\n",
        "X_weights = np.zeros(np.shape(X_train)[0])\n",
        "X_weights = X_weights + 1/np.shape(X_train)[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "7 Классификаторов"
      ],
      "metadata": {
        "id": "C1AT0J4I1TGE"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZfuoDDUs4Go",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bce90b18-d8cb-49d1-8c24-41ccce727d56"
      },
      "source": [
        "m = 7\n",
        "NN, accuracy, cl_err = train_commitee(m, X_train, y_train, X_weights, X_test, y_test)\n",
        "com_acc, std = get_commitee_accuracy(NN, cl_err, X_test, y_test)\n",
        "print('acc:',accuracy)\n",
        "print('com_acc:',com_acc)\n",
        "print('std:',std)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "acc: [0.5831759310449434, 0.5853782560044642, 0.6164123029231402, 0.6410719598941661, 0.6544995382675183, 0.6584421225812573, 0.6543249882410295]\n",
            "com_acc: 0.83\n",
            "std: 0.375632799419859\n"
          ]
        }
      ]
    }
  ]
}